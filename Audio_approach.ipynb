{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audio_approach.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c246969e9a2e4a7281c8673deaef2bab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "state": {
            "_view_name": "ButtonView",
            "style": "IPY_MODEL_ca6a3baf47c946a98d84a9c9b351b69d",
            "_dom_classes": [],
            "description": "Play Next",
            "_model_name": "ButtonModel",
            "button_style": "",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "tooltip": "",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "layout": "IPY_MODEL_8475d6e90dce440e91c0374fa3f18547",
            "_model_module": "@jupyter-widgets/controls",
            "icon": ""
          }
        },
        "ca6a3baf47c946a98d84a9c9b351b69d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ButtonStyleModel",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "button_color": null,
            "font_weight": "",
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8475d6e90dce440e91c0374fa3f18547": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df1e6fd5a4824104ada327d8fd5a5e0b": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": []
                },
                "text/html": "<iframe width=\"560\" height=\"315\" src=https://www.youtube.com/embed/_PwhiWxHK8o?start=1045&end=1055 frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>",
                "text/plain": "<IPython.core.display.HTML object>"
              },
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "Result  3\n",
                "stream": "stdout"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_cffe2a9810974d49b783f5d61208828c",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "cffe2a9810974d49b783f5d61208828c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EanPT9qZ3yC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "ca8920cd-3799-4f48-dd88-47f32ace508f"
      },
      "source": [
        "#enabling tensorflow with TPU support\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Tensorflow version 1.15.2\n",
            "Running on TPU  ['10.23.164.122:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: 10.23.164.122:8470\n",
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.23.164.122:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 4347880099433207690)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 5118217055574266196)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 10838393059695317128)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 14171044103703856116)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 9535503165042736035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 11083684434449499894)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 2939660575066410822)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 7178247587458283213)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 16919415141336061811)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 17653747852819255454)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 3235659215743019687)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCLyOGrHag5M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3168d0a7-a8b8-4db3-9d41-7d362905b60f"
      },
      "source": [
        "#Importing necessary modules\n",
        "print(tf.__version__)\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/1?tf-hub-format=compressed\"\n",
        "\n",
        "# Import the Universal Sentence Encoder's TF Hub module\n",
        "embed = hub.Module(module_url)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIPZplpLatPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to find semantic similarity of two sentences using Google's Universal Sentence Encoder\n",
        "def semantic_similarity(cap1,cap2):\n",
        "    messages=[cap1,cap2]\n",
        "    similarity_input_placeholder = tf.placeholder(tf.string, shape=(None))\n",
        "    similarity_message_encodings = embed(similarity_input_placeholder)\n",
        "    with tf.Session() as session:\n",
        "        session.run(tf.global_variables_initializer())\n",
        "        session.run(tf.tables_initializer())\n",
        "        message_embeddings_ = session.run(similarity_message_encodings, feed_dict={similarity_input_placeholder: messages})    \n",
        "    return cosine_similarity(message_embeddings_[0].reshape(1,-1),message_embeddings_[1].reshape(1,-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FuMMkyNawb2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "outputId": "1ba77843-4b19-42f8-ca8b-39ed2e4e55ff"
      },
      "source": [
        "#Installing necessary modules\n",
        "!pip install youtube-dl\n",
        "!pip install download-youtube-subtitle\n",
        "!pip install pafy\n",
        "!pip install ffmpeg-python\n",
        "!pip3 install --upgrade speechrecognition"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting youtube-dl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/5f/db1fb30596fbfabd3500e741cd9c73d0cb1d25387582fd21289bed05a9c2/youtube_dl-2020.6.16.1-py2.py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 3.5MB/s \n",
            "\u001b[?25hInstalling collected packages: youtube-dl\n",
            "Successfully installed youtube-dl-2020.6.16.1\n",
            "Collecting download-youtube-subtitle\n",
            "  Downloading https://files.pythonhosted.org/packages/55/6d/b6765a521338cc55480a49eab611aa7d1d78ef37e683ec3ab5d42b08635c/download-youtube-subtitle-1.0.1.tar.gz\n",
            "Collecting fire\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/a7/0e22e70778aca01a52b9c899d9c145c6396d7b613719cd63db97ffa13f2f/fire-0.3.1.tar.gz (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from download-youtube-subtitle) (2.23.0)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.6/dist-packages (from download-youtube-subtitle) (5.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire->download-youtube-subtitle) (1.12.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire->download-youtube-subtitle) (1.1.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->download-youtube-subtitle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->download-youtube-subtitle) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->download-youtube-subtitle) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->download-youtube-subtitle) (2020.6.20)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from IPython->download-youtube-subtitle) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from IPython->download-youtube-subtitle) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from IPython->download-youtube-subtitle) (4.3.3)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from IPython->download-youtube-subtitle) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from IPython->download-youtube-subtitle) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from IPython->download-youtube-subtitle) (49.1.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from IPython->download-youtube-subtitle) (2.1.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from IPython->download-youtube-subtitle) (4.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->download-youtube-subtitle) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->IPython->download-youtube-subtitle) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->IPython->download-youtube-subtitle) (0.6.0)\n",
            "Building wheels for collected packages: download-youtube-subtitle, fire\n",
            "  Building wheel for download-youtube-subtitle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for download-youtube-subtitle: filename=download_youtube_subtitle-1.0.1-cp36-none-any.whl size=8796 sha256=747de47d09b9cdf109e0d54f11c4d67289c7d09f82449cec54ccf398498e9d41\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/90/d3/77d2a80c78c00533592d4c8200d4d213e1601aa1b396e85ad8\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111005 sha256=d6004327a0af28c90800f06c67d84f54c8b18de32c352d1f6ad2426e50d88aaa\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/61/df/768b03527bf006b546dce284eb4249b185669e65afc5fbb2ac\n",
            "Successfully built download-youtube-subtitle fire\n",
            "Installing collected packages: fire, download-youtube-subtitle\n",
            "Successfully installed download-youtube-subtitle-1.0.1 fire-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3mJjhsknqea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input =  '_PwhiWxHK8o'#@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTrlOvKCf4-G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "70ccb85b-ed5f-4606-a472-4b03a54a76ee"
      },
      "source": [
        "#Generating the subtitle file for the given ID\n",
        "import os\n",
        "os.system('dl-youtube-cc '+input+' --translation False --to_json=True --output_file=\"input.json\"')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7Nrs9BVoc7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reading the subtitle file generated\n",
        "import json\n",
        "f=open(r\"/content/input.json\")\n",
        "data=json.load(f)[\"original\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS3HlEPAoxMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Filtering\n",
        "transcript=[]\n",
        "for i in range(len(data)-1):\n",
        "  if(data[i]['text']):\n",
        "    transcript.append([data[i]['text'].replace('\\n',' '),[float(data[i]['start']),float(data[i+1]['start'])]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhY6dUarozki",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b835631d-0a66-47fd-ff3a-919511f65698"
      },
      "source": [
        "len(transcript)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "868"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J961NVeto4l-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Finding the length of the input Video\n",
        "import pafy\n",
        "url = \"https://youtu.be/\"+input\n",
        "video = pafy.new(url)\n",
        "length=video.length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-14RKQHTo6YV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Getting the last transcript\n",
        "if(data[-1][\"text\"]):\n",
        "  transcript.append([data[-1]['text'].replace('\\n',' '),[float(data[-1]['start']),length]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awKdS3Rio8jn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f824eb20-83c7-4019-aacd-b2f68d160e78"
      },
      "source": [
        "transcript"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['PATRICK WINSTON: So where are we?', [9.234, 10.3]],\n",
              " ['We started off with simple methods for learning stuff.', [10.3, 14.962]],\n",
              " ['Then, we talked a little about a purchase of learning that',\n",
              "  [14.962, 20.73]],\n",
              " [\"we're vaguely inspired by.\", [20.73, 24.556]],\n",
              " ['The fact that our heads are stuffed with neurons, and that',\n",
              "  [24.556, 27.3]],\n",
              " ['we seemed to have evolved from primates.', [27.3, 31.095]],\n",
              " ['Then, we talked about looking at the problem and address the',\n",
              "  [31.095, 34.94]],\n",
              " ['issue of [? phrenology ?]', [34.94, 36.41]],\n",
              " [\"and how it's possible to learn concepts.\", [36.41, 40.43]],\n",
              " [\"But now, we're coming full circle back to the beginning\", [40.43, 43.7]],\n",
              " ['and thinking about how to divide up a space with', [43.7, 47.99]],\n",
              " ['decision boundaries.', [47.99, 49.93]],\n",
              " ['But whereas, you do it with a neural net or a nearest', [49.93, 54.58]],\n",
              " ['neighbors or a ID tree.', [54.58, 56.51]],\n",
              " ['Those are very simple ideas that work very often.', [56.51, 62.115]],\n",
              " [\"Today, we're going to talk about a very sophisticated\", [62.115, 65.895]],\n",
              " ['idea that still has a implementation.', [65.895, 69.212]],\n",
              " ['So this needs to be in the tool bag of', [69.212, 73.22]],\n",
              " ['every civilized person.', [73.22, 75.506]],\n",
              " ['This is about support vector machines, an', [75.506, 78.56]],\n",
              " ['idea that was developed.', [78.56, 80.735]],\n",
              " ['Well, I want to talk to you today about how', [80.735, 82.47]],\n",
              " ['ideas develop, actually.', [82.47, 84.705]],\n",
              " ['Because you look at stuff like this in a book, and you think,',\n",
              "  [84.705, 87.15]],\n",
              " ['well, Vladimir Vapnik just figured this out one Saturday', [87.15, 92.515]],\n",
              " ['afternoon when the weather was too bad to go outside.', [92.515, 95.78]],\n",
              " [\"That's not how it happens.\", [95.78, 97.185]],\n",
              " ['It happens very differently.', [97.185, 98.58]],\n",
              " ['I want to talk to you a little about that.', [98.58, 101.23]],\n",
              " ['The next thing about great things that were done by', [101.23, 106.95]],\n",
              " ['people who are still alive is you can ask them', [106.95, 109.06]],\n",
              " ['how they did it.', [109.06, 110.21]],\n",
              " [\"You can't do that with Fourier.\", [110.21, 111.81]],\n",
              " [\"You can't say to Fourier, how did you do it?\", [111.81, 114.31]],\n",
              " ['Did you dream it up on a Saturday afternoon?', [114.31, 116.946]],\n",
              " ['But can call Vapnik on the phone and ask him questions.',\n",
              "  [116.946, 120.22]],\n",
              " [\"That's the stuff I'm going to talk about toward\", [120.22, 122.05]],\n",
              " ['the end of the hour.', [122.05, 124.186]],\n",
              " [\"Well, it's all about decision boundaries.\", [124.186, 126.045]],\n",
              " ['And now, we have several techniques that we can use to', [126.045, 131.4]],\n",
              " ['draw some decision boundaries.', [131.4, 132.62]],\n",
              " [\"And here's the same problem.\", [132.62, 134.7]],\n",
              " ['And if we drew decision boundaries in here, we might', [134.7, 138.33]],\n",
              " ['get something that would look like maybe this.', [138.33, 141.826]],\n",
              " ['If we were doing a nearest neighbor approach, and if', [141.826, 145.79]],\n",
              " [\"we're doing ID trees, we'll just draw in a line like that.\",\n",
              "  [145.79, 151.522]],\n",
              " [\"And if we're doing neural nets, well, you can put in a\",\n",
              "  [151.522, 154.945]],\n",
              " ['lot of straight lines wherever you like with a neural net,',\n",
              "  [154.945, 157.55]],\n",
              " [\"depending on how it's trained up.\", [157.55, 159.11]],\n",
              " ['Or if you just simply go in there and design it, so you', [159.11, 162.47]],\n",
              " ['could do that if you wanted.', [162.47, 165.554]],\n",
              " ['And you would think that after people have been working on',\n",
              "  [165.554, 168.11]],\n",
              " [\"this sort of stuff for 50 or 75 years that there wouldn't\",\n",
              "  [168.11, 172.5]],\n",
              " ['be any tricks in the bag left.', [172.5, 174.535]],\n",
              " [\"And that's when everybody got surprised, because around the\",\n",
              "  [174.535, 179.34]],\n",
              " [\"early '90s Vladimir Vapnik introduced the ideas I'm about\",\n",
              "  [179.34, 183.88]],\n",
              " ['to talk to you about.', [183.88, 185.916]],\n",
              " ['So what Vapnik says is something like this.', [185.916, 191.215]],\n",
              " ['Here you have a space, and you have some negative examples,',\n",
              "  [191.215, 197.47]],\n",
              " ['and you have some positive examples.', [197.47, 200.436]],\n",
              " ['How do you divide the positive examples from', [200.436, 202.87]],\n",
              " ['the negative examples?', [202.87, 204.22]],\n",
              " ['And what he says that we want to do is we want to draw a',\n",
              "  [204.22, 207.71]],\n",
              " ['straight line.', [207.71, 209.14]],\n",
              " ['But which straight line is the question.', [209.14, 212.062]],\n",
              " ['Well, we want to draw a straight line.', [212.062, 215.14]],\n",
              " ['Well, would this be a good straight line?', [215.14, 218.141]],\n",
              " ['One that went up like that?', [218.141, 220.492]],\n",
              " ['Probably not so hot.', [220.492, 222.66]],\n",
              " [\"How about one that's just right here?\", [222.66, 225.622]],\n",
              " ['Well, that might separate them, but it seems awfully', [225.622, 229.46]],\n",
              " ['close to the negative examples.', [229.46, 231.765]],\n",
              " ['So maybe what we ought to do is we ought to draw our', [231.765, 235.03]],\n",
              " ['straight line in here, sort of like this.', [235.03, 237.22]],\n",
              " ['And that line is drawn with a view toward putting in the',\n",
              "  [240.458, 247.59]],\n",
              " ['widest street that separates the positive samples from the',\n",
              "  [247.59, 253.33]],\n",
              " ['negative samples.', [253.33, 254.46]],\n",
              " [\"That's why I call it the widest street approach.\", [254.46, 257.209]],\n",
              " ['So that makes way of putting in the decision boundary--',\n",
              "  [257.209, 261.535]],\n",
              " ['is to put in a straight line but in contrast with the way',\n",
              "  [261.535, 265.56]],\n",
              " ['ID tree puts in a straight line.', [265.56, 267.44]],\n",
              " ['It tries to put the line in in such a way as the separation',\n",
              "  [267.44, 272.165]],\n",
              " ['between the positive and negative examples.', [272.165, 274.68]],\n",
              " ['That street is as wide as possible.', [274.68, 277.236]],\n",
              " ['All right.', [277.236, 277.722]],\n",
              " ['So you might think to do that in the UROP project, and then,',\n",
              "  [277.722, 281.62]],\n",
              " ['let it go with that.', [281.62, 283.205]],\n",
              " [\"What's the big deal?\", [283.205, 284.73]],\n",
              " [\"So what we've got to do is we've got to go through why\", [284.73, 287.34]],\n",
              " [\"it's a big deal.\", [287.34, 289.176]],\n",
              " ['So first of all, we like to think about how you would make',\n",
              "  [289.176, 295.17]],\n",
              " ['a decision rule that would use that decision boundary.', [295.17, 299.326]],\n",
              " [\"So what I'm going to ask you to imagine is that we've got a\",\n",
              "  [299.326, 303.65]],\n",
              " ['vector of any length that you like, constrained to be', [303.65, 309.65]],\n",
              " ['perpendicular to the median, or if you like, perpendicular',\n",
              "  [309.65, 313.715]],\n",
              " ['to the gutters.', [313.715, 314.63]],\n",
              " [\"It's perpendicular to the median line of the street.\", [314.63, 318.28]],\n",
              " [\"All right, it's drawn in such a way that that's true.\", [318.28, 320.54]],\n",
              " [\"We don't know anything about it's length, yet.\", [320.54, 323.984]],\n",
              " ['Then, we also have some unknown, say, right here.', [323.984, 329.92]],\n",
              " ['And we have a vector that points to it by excel.', [329.92, 335.325]],\n",
              " [\"So now, what we're really interested in is whether or\", [335.325, 339.31]],\n",
              " ['not that unknown is on the right side of the street or on',\n",
              "  [339.31, 342.92]],\n",
              " ['the left side of the street.', [342.92, 345.062]],\n",
              " [\"So what we'd what to do is want to project that vector,\",\n",
              "  [345.062, 347.91]],\n",
              " [\"u, down on to one that's perpendicular to the street.\", [347.91, 351.99]],\n",
              " [\"Because then, we'll have the distance in this direction or\",\n",
              "  [351.99, 355.205]],\n",
              " [\"a number that's proportional to this in this direction.\",\n",
              "  [355.205, 358.49]],\n",
              " [\"And the further out we go, the closer we'll get to being on\",\n",
              "  [358.49, 362.67]],\n",
              " ['the right side of the street, where the right side of the',\n",
              "  [362.67, 365.36]],\n",
              " ['street is not the correct side but actually the right side of',\n",
              "  [365.36, 368.065]],\n",
              " ['the street.', [368.065, 368.985]],\n",
              " [\"So what we can do is we can say, let's take w and dot it\",\n",
              "  [368.985, 374.28]],\n",
              " ['with u and measure whether or not that number is equal to or',\n",
              "  [374.28, 379.93]],\n",
              " ['greater than some constant, c.', [379.93, 382.646]],\n",
              " ['So remember that the dot product has taken the', [382.646, 385.88]],\n",
              " ['projection onto w.', [385.88, 387.896]],\n",
              " ['And the bigger that projection is, the further out along this',\n",
              "  [387.896, 392.15]],\n",
              " ['line the projection will lie.', [392.15, 394.255]],\n",
              " ['And eventually it will be so big that the projection', [394.255, 397.49]],\n",
              " [\"crosses the median line of the street, and we'll say it must\",\n",
              "  [397.49, 400.44]],\n",
              " ['be a positive sample.', [400.44, 401.69]],\n",
              " ['Or we could say, without loss of generality that the dot',\n",
              "  [405.708, 410.88]],\n",
              " ['product plus some constant, b, is equal to or greater than 0.',\n",
              "  [410.88, 416.36]],\n",
              " [\"If that's true, then it's a positive sample.\", [416.36, 423.05]],\n",
              " [\"So that's our decision rule.\", [423.05, 424.3]],\n",
              " [\"And this is the first in several elements that we're\", [431.522, 437.3]],\n",
              " ['going to have to line up to understand this idea called', [437.3, 440.96]],\n",
              " ['support vector machines.', [440.96, 443.34]],\n",
              " [\"So that's the decision rule.\", [443.34, 444.73]],\n",
              " [\"And the trouble is we don't know what constant to use, and\",\n",
              "  [444.73, 449.46]],\n",
              " [\"we don't know which w to use either.\", [449.46, 452.45]],\n",
              " ['We know that w has to be perpendicular to the median', [452.45, 455.39]],\n",
              " ['line of the street.', [455.39, 457.476]],\n",
              " [\"But there's lot of w's that are perpendicular to the\", [457.476, 459.88]],\n",
              " ['median line of the street, because it', [459.88, 461.07]],\n",
              " ['could be of any length.', [461.07, 462.74]],\n",
              " [\"So we don't have enough constraint here to fix a\", [462.74, 465.75]],\n",
              " ['particular b or a particular w.', [465.75, 469.532]],\n",
              " ['Are you with me so far?', [469.532, 472.395]],\n",
              " ['All right.', [472.395, 475.176]],\n",
              " ['And this, by the way, we get just by saying that c', [475.176, 477.99]],\n",
              " ['equals minus b.', [477.99, 479.24]],\n",
              " [\"What we're going to do next is we're going to lay on some\",\n",
              "  [482.8, 485.79]],\n",
              " [\"additional constraints whether you're toward putting enough\",\n",
              "  [485.79, 488.96]],\n",
              " ['constraint on the situation that we can actually calculate',\n",
              "  [488.96, 493.33]],\n",
              " ['a b and a w.', [493.33, 496.015]],\n",
              " [\"So what we're going to say is this, that if we look at this\",\n",
              "  [496.015, 501.29]],\n",
              " [\"quantity that we're checking out to be greater than or less\",\n",
              "  [501.29, 504.68]],\n",
              " [\"than 0 to make our decision, then, what we're going to do\",\n",
              "  [504.68, 508.04]],\n",
              " [\"is we're going to say that if we take that vector w, and we\",\n",
              "  [508.04, 512.51]],\n",
              " ['take the dot product of that with some x plus, some', [512.51, 517.789]],\n",
              " ['positive sample, now.', [517.789, 518.929]],\n",
              " ['This is not an unknown.', [518.929, 519.76]],\n",
              " ['This is a positive sample.', [519.76, 522.272]],\n",
              " ['If we take the dot product of those two vectors, and we had',\n",
              "  [522.272, 526.5]],\n",
              " [\"b just like in our decision rule, we're going to want that\",\n",
              "  [526.5, 530.05]],\n",
              " ['to be equal to or greater than 1.', [530.05, 531.37]],\n",
              " ['So in other words, you can be an unknown anywhere in this',\n",
              "  [534.22, 539.08]],\n",
              " ['street and be just a little bit greater or just a little',\n",
              "  [539.08, 542.14]],\n",
              " ['bit less than 0.', [542.14, 543.61]],\n",
              " [\"But if you're a positive sample, we're going to insist\", [543.61, 546.12]],\n",
              " ['that this decision function gives the', [546.12, 548.55]],\n",
              " ['value of one or greater.', [548.55, 551.476]],\n",
              " ['Likewise, if w thought it was some negative sample is', [551.476, 561.03]],\n",
              " [\"provided to us, then we're going to say that has to be\", [561.03, 564.38]],\n",
              " ['equal to or less than minus 1.', [564.38, 565.8]],\n",
              " ['All right.', [568.69, 569.866]],\n",
              " [\"So if you're a minus sample, like one of these two guys or\",\n",
              "  [569.866, 573.79]],\n",
              " ['any minus sample that may lie down here, this function that',\n",
              "  [573.79, 578.33]],\n",
              " ['gives us the decision rule must return minus 1 or less.',\n",
              "  [578.33, 582.506]],\n",
              " [\"So there's a separation of distance here.\", [582.506, 585.02]],\n",
              " ['Minus 1 to plus 1 for all of the samples.', [585.02, 586.93]],\n",
              " [\"So that's cool.\", [590.717, 592.842]],\n",
              " [\"But we're not quite done, because carrying around two\", [592.842, 598.29]],\n",
              " [\"equations like this, it's a pain.\", [598.29, 601.534]],\n",
              " [\"So what we're going to do is we're going to introduce\", [601.534, 604.76]],\n",
              " ['another variable to make like a little easier.', [604.76, 608.19]],\n",
              " ['Like many things that we do, and when we develop this kind',\n",
              "  [611.502, 615.21]],\n",
              " ['of stuff, introducing this variable is not something that',\n",
              "  [615.21, 619.12]],\n",
              " ['God says has to be done.', [619.12, 620.37]],\n",
              " ['What is it?', [624.38, 625.31]],\n",
              " ['We introduced this additional stuff to do what?', [625.31, 628.93]],\n",
              " ['To make the mathematics more convenient, so mathematical',\n",
              "  [628.93, 634.14]],\n",
              " ['convenience.', [634.14, 635.822]],\n",
              " [\"So what we're going to do is we're going to introduce a\",\n",
              "  [635.822, 637.73]],\n",
              " ['variable, y sub i, such that y sub i is equal to plus 1 for',\n",
              "  [637.73, 653.6]],\n",
              " ['plus samples and minus 1 for negative samples.', [653.6, 670.46]],\n",
              " ['All right.', [670.46, 671.685]],\n",
              " [\"So for each sample, we're going to have a value for this\",\n",
              "  [671.685, 674.19]],\n",
              " [\"new quantity we've introduced, y.\", [674.19, 676.68]],\n",
              " [\"And the value of y is going to be determined by whether it's\",\n",
              "  [676.68, 679.91]],\n",
              " ['a positive sample or negative sample.', [679.91, 682.37]],\n",
              " [\"If it's a positive sample it's got to be plus 1 for this\", [682.37, 686.6]],\n",
              " [\"situation up here, and it's going to be minus 1 for this\", [686.6, 689.28]],\n",
              " ['situation down here.', [689.28, 691.235]],\n",
              " [\"So what we're going to do with this first equation is we're\",\n",
              "  [691.235, 694.48]],\n",
              " ['going to multiply it by y sub i, and that is now x of i,',\n",
              "  [694.48, 701.605]],\n",
              " ['plus b is equal to or greater than 1.', [701.605, 706.43]],\n",
              " [\"And then, you know what we're going to do?\", [706.43, 707.74]],\n",
              " [\"We're going to multiply the left side of this equation by\",\n",
              "  [707.74, 713.03]],\n",
              " ['y sub i, as well.', [713.03, 714.77]],\n",
              " ['So the second equation becomes y sub i times x sub i plus b.',\n",
              "  [714.77, 723.172]],\n",
              " ['And now, what does that do over here?', [723.172, 725.876]],\n",
              " ['We multiplied this guy times minus 1.', [725.876, 729.48]],\n",
              " ['So it used to be the case that that was less than minus 1.',\n",
              "  [729.48, 732.75]],\n",
              " ['So if we multiply it by minus 1, then it has to be greater',\n",
              "  [732.75, 734.9]],\n",
              " ['than plus 1.', [734.9, 736.15]],\n",
              " ['The two equations are the same, because that introduces', [738.99, 743.22]],\n",
              " ['this little mathematical convenience.', [743.22, 746.58]],\n",
              " ['So now, we can say that y sub i times x sub i plus b.', [746.58, 755.43]],\n",
              " [\"Well, what we're going to do--\", [757.986, 761.826]],\n",
              " ['Brett?', [761.826, 762.675]],\n",
              " ['STUDENT: What happened to the w?', [762.675, 764.255]],\n",
              " ['PATRICK WINSTON: Oh, did I leave out a w?', [764.255, 765.45]],\n",
              " [\"I'm sorry.\", [765.45, 766.05]],\n",
              " ['Thank you.', [766.05, 768.612]],\n",
              " [\"Yeah, I wouldn't have gotten very far with that.\", [768.612, 771.561]],\n",
              " [\"So that's dot it with w, dot it with w.\", [771.561, 774.21]],\n",
              " ['Thank you, Brett.', [774.21, 775.605]],\n",
              " ['Those are all vectors.', [775.605, 776.71]],\n",
              " [\"I'll pretty soon forget to put the little vector marks on\",\n",
              "  [776.71, 780.01]],\n",
              " ['there, but you know what I mean.', [780.01, 781.09]],\n",
              " [\"So that's w plus b.\", [781.09, 785.256]],\n",
              " ['And now, let me bring that 1 over to the left side, and',\n",
              "  [785.256, 789.66]],\n",
              " [\"that's equal to or greater than 0.\", [789.66, 791.01]],\n",
              " ['All right.', [793.535, 794.73]],\n",
              " [\"With Brett's correction, I think everything's OK.\", [794.73, 797.44]],\n",
              " [\"But we're going to take one more step, and we're going to\",\n",
              "  [797.44, 801.01]],\n",
              " ['say that y sub i times x sub i times w plus b minus 1.', [801.01, 811.27]],\n",
              " [\"It's always got to be equal to or greater than 0.\", [813.885, 815.76]],\n",
              " [\"But what I'm going to say is if we're for\", [815.76, 822.492]],\n",
              " ['x sub i in a gutter.', [822.492, 824.55]],\n",
              " [\"So there's always going to be greater than 0, but we're\",\n",
              "  [829.092, 831.14]],\n",
              " [\"going to add the additional constraint that it's going to\",\n",
              "  [831.14, 833.54]],\n",
              " ['be exactly 0 for all the samples that end up in the', [833.54, 838.3]],\n",
              " ['gutters here of the street.', [838.3, 840.19]],\n",
              " ['So the value of that expression is going to be', [840.19, 843.01]],\n",
              " ['exactly 0 for that sample, 0 for this sample and this', [843.01, 848.39]],\n",
              " ['sample, not 0 for that sample.', [848.39, 850.46]],\n",
              " [\"It's got to be greater than 1.\", [850.46, 852.18]],\n",
              " ['All right?', [852.18, 853.846]],\n",
              " [\"So that's step number two.\", [853.846, 856.76]],\n",
              " ['And this is step number one.', [865.319, 867.14]],\n",
              " ['OK.', [871.454, 871.95]],\n",
              " [\"So now, we've just got some expressions to talk about,\", [871.95, 874.34]],\n",
              " ['some constraints.', [874.34, 876.416]],\n",
              " ['Now, what are we trying to do here?', [876.416, 877.87]],\n",
              " ['I forgot.', [877.87, 879.922]],\n",
              " ['Oh, I remember now.', [879.922, 881.32]],\n",
              " [\"We're trying to figure out how to arrange for the line to be\",\n",
              "  [881.32, 885.5]],\n",
              " ['such at the street separating the pluses from the minuses as',\n",
              "  [885.5, 888.79]],\n",
              " ['wide as possible.', [888.79, 891.121]],\n",
              " ['So maybe we better figure out how we can express the', [891.121, 894.3]],\n",
              " ['distance between the two gutters.', [894.3, 896.13]],\n",
              " [\"Let's just repeat our drawing.\", [903.645, 906.822]],\n",
              " [\"We've got some minuses here, got pluses out here, and we've\",\n",
              "  [906.822, 912.03]],\n",
              " ['got gutters that are going down here.', [912.03, 917.021]],\n",
              " [\"And now, we've got a vector here to a minus, and we've got\",\n",
              "  [917.021, 922.29]],\n",
              " ['a vector here to a plus.', [922.29, 927.091]],\n",
              " [\"So we'll call that x plus and this x minus.\", [927.091, 933.95]],\n",
              " [\"So what's the width of the street?\", [933.95, 936.73]],\n",
              " [\"I don't know, yet.\", [936.73, 937.6]],\n",
              " ['But what we can do is we can take the difference of those',\n",
              "  [937.6, 940.36]],\n",
              " ['two vectors, and that will be a vector that', [940.36, 944.12]],\n",
              " ['looks like this, right?', [944.12, 946.346]],\n",
              " [\"So that's x plus minus x minus.\", [946.346, 952.016]],\n",
              " [\"So now, if I only had a unit normal that's normal to the\",\n",
              "  [952.016, 956.28]],\n",
              " [\"median line of the street, if it's a unit normal, then I\",\n",
              "  [956.28, 960.32]],\n",
              " ['could just take the dot product or that unit normal', [960.32, 962.12]],\n",
              " ['and this difference vector, and that would be the width of',\n",
              "  [962.12, 963.975]],\n",
              " ['the street, right?', [963.975, 965.98]],\n",
              " ['So in other words, if I had a unit vector in that direction,',\n",
              "  [965.98, 973.09]],\n",
              " ['then I could just dot the two together, and that would be',\n",
              "  [973.09, 975.53]],\n",
              " ['the width of the street.', [975.53, 977.896]],\n",
              " ['So let me write that down before I forget.', [977.896, 981.55]],\n",
              " ['So the width is equal to x plus minus x minus.', [981.55, 991.625]],\n",
              " ['OK.', [991.625, 994.396]],\n",
              " [\"That's the difference vector.\", [994.396, 995.58]],\n",
              " [\"And now, I've got to multiple it by unit vector.\", [995.58, 997.51]],\n",
              " ['But wait a minute.', [997.51, 998.18]],\n",
              " ['I said that that w is a normal, right?', [998.18, 1001.59]],\n",
              " ['The w is a normal.', [1001.59, 1004.032]],\n",
              " ['So what I can do is I can multiply this times w, and',\n",
              "  [1004.032, 1010.018]],\n",
              " [\"then, we'll divide by the magnitude of w, and that will\",\n",
              "  [1010.018, 1014.156]],\n",
              " ['make it a unit vector.', [1014.156, 1016.591]],\n",
              " ['So that dot product, not a product, that dot product is,',\n",
              "  [1016.591, 1025.65]],\n",
              " [\"in fact, a scalar, and it's the width of the street.\", [1025.65, 1030.329]],\n",
              " [\"It doesn't do as much good, because it doesn't look like\",\n",
              "  [1030.329, 1034.73]],\n",
              " ['we get much out of it.', [1034.73, 1037.053]],\n",
              " [\"Oh, but I don't know.\", [1037.053, 1038.22]],\n",
              " [\"Let's see, what can we get out of it?\", [1038.22, 1041.371]],\n",
              " [\"Oh gee, we've got this equation over here, this\", [1041.371, 1045.954]],\n",
              " ['equation that constrains the samples', [1045.954, 1048.594]],\n",
              " ['that lie in the gutter.', [1048.594, 1051.31]],\n",
              " ['So if we have a positive sample, for example, then this',\n",
              "  [1051.31, 1055.61]],\n",
              " ['is plus 1, and we have this equation.', [1055.61, 1058.53]],\n",
              " ['So it says that x plus times w is equal to, oh, 1 minus b.',\n",
              "  [1061.15, 1073.9]],\n",
              " [\"See, I'm just taking this part here, this vector here, and\",\n",
              "  [1078.492, 1082.21]],\n",
              " [\"I'm dotting it with x plus.\", [1082.21, 1084.88]],\n",
              " [\"So that's this piece right here.\", [1084.88, 1088.65]],\n",
              " ['y is 1 for this kind of sample.', [1088.65, 1091.23]],\n",
              " [\"So I'll just take the 1 and the b back over to the other\",\n",
              "  [1091.23, 1093.6]],\n",
              " [\"side, and I've got 1 minus b.\", [1093.6, 1096.212]],\n",
              " ['OK?', [1096.212, 1098.592]],\n",
              " ['Well, we can do the same trick with x minus.', [1098.592, 1102.241]],\n",
              " [\"If we've got a negative sample,\", [1102.241, 1104.806]],\n",
              " ['then y sub i is negative.', [1104.806, 1108.572]],\n",
              " ['That gives us our negative w times dot over x sub i.',\n",
              "  [1108.572, 1114.296]],\n",
              " ['But now, we take this stuff back over to the right side,',\n",
              "  [1114.296, 1117.19]],\n",
              " ['and we get 1 plus b.', [1117.19, 1120.54]],\n",
              " ['So that all licenses to rewrite this thing as 2 over', [1125.252, 1130.2]],\n",
              " ['the magnitude of w.', [1130.2, 1132.646]],\n",
              " ['How did I get there?', [1132.646, 1134.21]],\n",
              " ['Well, I decided I was going to enforce this constraint.',\n",
              "  [1134.21, 1139.27]],\n",
              " ['I noted that the width of the street has got to be this',\n",
              "  [1139.27, 1143.54]],\n",
              " ['difference vector times a unit vector.', [1143.54, 1146.105]],\n",
              " ['Then, I used the constraint to plug back some values here.',\n",
              "  [1146.105, 1149.4]],\n",
              " ['And I discovered to my delight and amazement that the width',\n",
              "  [1149.4, 1152.48]],\n",
              " ['of the street is 2 over the magnitude of w.', [1152.48, 1155.35]],\n",
              " ['Yes, Brett?', [1158.34, 1160.388]],\n",
              " ['STUDENT: So your first x plus is minus b, and x', [1160.388, 1163.881]],\n",
              " ['minus is 1 plus b.', [1163.881, 1165.378]],\n",
              " ['PATRICK WINSTON: Yeah.', [1165.378, 1165.877]],\n",
              " [\"STUDENT: So you're subtracting it?\", [1165.877, 1166.875]],\n",
              " [\"PATRICK WINSTON: Let's see.\", [1166.875, 1167.75]],\n",
              " [\"If I've got a minus here, then that makes that minus, and\",\n",
              "  [1167.75, 1171.855]],\n",
              " ['then, the b is minus, and when I take the b over to the other',\n",
              "  [1171.855, 1173.81]],\n",
              " ['side it becomes plus.', [1173.81, 1175.579]],\n",
              " ['STUDENT: Yeah, so if you subtract the left with the', [1175.579, 1178.573]],\n",
              " ['right [INAUDIBLE].', [1178.573, 1181.068]],\n",
              " ['PATRICK WINSTON: No.', [1181.068, 1181.67]],\n",
              " ['No, sorry.', [1181.67, 1182.32]],\n",
              " ['This expression here is 1 plus b.', [1182.32, 1186.981]],\n",
              " ['Trust me it works.', [1186.981, 1188.87]],\n",
              " [\"I haven't got my legs all tangled up like last Friday,\",\n",
              "  [1188.87, 1191.37]],\n",
              " ['well, not yet, anyway.', [1191.37, 1193.786]],\n",
              " [\"It's possible.\", [1193.786, 1195.34]],\n",
              " [\"There's going to be a lot of algebra here eventually.\",\n",
              "  [1195.34, 1198.958]],\n",
              " ['So this quantity here, this is miracle number three.',\n",
              "  [1198.958, 1204.995]],\n",
              " ['This quantity here is the width of the street.', [1204.995, 1209.731]],\n",
              " [\"And what we're trying to do is we're trying to\", [1209.731, 1213.57]],\n",
              " ['maximize that, right?', [1213.57, 1217.158]],\n",
              " [\"So we want to maximize 2 over the magnitude of w if we're to\",\n",
              "  [1217.158, 1227.17]],\n",
              " [\"get the widest street under the constraints that we've\", [1227.17, 1229.3]],\n",
              " [\"decided that we're going to work with.\", [1229.3, 1232.21]],\n",
              " ['All right.', [1232.21, 1233.05]],\n",
              " [\"So that means that it's OK to maximize 1 over w, instead.\",\n",
              "  [1233.05, 1246.281]],\n",
              " ['We just drop the constant.', [1246.281, 1248.25]],\n",
              " [\"And that means that it's OK to minimize the\", [1248.25, 1253.55]],\n",
              " ['magnitude of w, right?', [1253.55, 1256.15]],\n",
              " [\"And that means that it's OK to minimize 1/2 times the\",\n",
              "  [1259.572, 1268.71]],\n",
              " ['magnitude of w squared.', [1268.71, 1272.07]],\n",
              " ['Right, Brett?', [1272.07, 1273.675]],\n",
              " ['Why did I do that?', [1273.675, 1276.075]],\n",
              " ['Why did I multiply by 1/2 and square it?', [1276.075, 1279.01]],\n",
              " [\"STUDENT: Because it's mathematically convenient.\", [1279.01, 1279.97]],\n",
              " [\"PATRICK WINSTON: It's mathematically convenient.\", [1279.97, 1280.93]],\n",
              " ['Thank you.', [1280.93, 1282.85]],\n",
              " ['So this is point number three in the development.', [1282.85, 1287.84]],\n",
              " ['So where do we go?', [1287.84, 1288.95]],\n",
              " ['We decided that was going to be our decision rule.', [1288.95, 1291.17]],\n",
              " [\"We're going to see which side of the line we're on.\", [1291.17, 1293.53]],\n",
              " ['We decided to constrain the situation, so the value of the',\n",
              "  [1293.53, 1296.42]],\n",
              " ['decision rule is plus 1 in the gutters for the positive',\n",
              "  [1296.42, 1300.75]],\n",
              " ['samples and minus 1 in the gutters for', [1300.75, 1302.82]],\n",
              " ['the negative samples.', [1302.82, 1304.07]],\n",
              " ['And then, we discovered that maximizing the width of the',\n",
              "  [1304.07, 1307.47]],\n",
              " ['street led us to an expression like that,', [1307.47, 1311.09]],\n",
              " ['which we wish to maximize.', [1311.09, 1312.34]],\n",
              " ['Should we take a break?', [1317.425, 1318.35]],\n",
              " ['Should we get coffee?', [1318.35, 1319.46]],\n",
              " [\"Too bad, we can't do that in this kind of situation.\", [1319.46, 1322.365]],\n",
              " ['But we would if we could.', [1322.365, 1324.4]],\n",
              " [\"And I'm sure when Vapnik got to this point, he\", [1324.4, 1327.09]],\n",
              " ['went out for coffee.', [1327.09, 1329.826]],\n",
              " [\"So now, we back up, and we say, well, let's let these\",\n",
              "  [1329.826, 1333.82]],\n",
              " ['expressions start developing into a song.', [1333.82, 1337.252]],\n",
              " [\"Not like that, that's vapid, speaking of Vapnik.\", [1337.252, 1341.03]],\n",
              " ['What song is it going to sing?', [1349.76, 1351.97]],\n",
              " [\"We've got an expression here that we'd like to find the\",\n",
              "  [1351.97, 1355.68]],\n",
              " ['minimum of, the extremum of.', [1355.68, 1358.236]],\n",
              " [\"And we've got some constraints here that we\", [1358.236, 1361.79]],\n",
              " ['would like to honor.', [1361.79, 1364.04]],\n",
              " ['What are we going to do?', [1364.04, 1365.29]],\n",
              " [\"Let me put what we're going to do to you in\", [1367.6, 1369.3]],\n",
              " ['the form of a puzzle.', [1369.3, 1372.385]],\n",
              " ['Is it got something to do with Legendre?', [1372.385, 1378.9]],\n",
              " ['Has it got something to do with Laplace?', [1378.9, 1384.27]],\n",
              " ['Or does it have something to do with Lagrange?', [1384.27, 1387.375]],\n",
              " ['She says Lagrange.', [1387.375, 1389.4]],\n",
              " [\"Actually, all three were said to be on Fourier's Doctoral\",\n",
              "  [1389.4, 1392.85]],\n",
              " ['Defense Committee-- must have been quite an example.', [1392.85, 1395.59]],\n",
              " [\"But we want to talk about Lagrange, because we've got a\",\n",
              "  [1395.59, 1398.96]],\n",
              " ['situation here.', [1398.96, 1400.605]],\n",
              " ['Is this 1801?', [1400.605, 1402.06]],\n",
              " ['1802?', [1402.06, 1402.84]],\n",
              " ['1802.', [1402.84, 1405.0]],\n",
              " ['We learned in 1802 that if we going to find the extremum of',\n",
              "  [1405.0, 1408.462]],\n",
              " [\"a function with constraints, then we're going to have to\",\n",
              "  [1408.462, 1413.84]],\n",
              " ['use Lagrange multipliers.', [1413.84, 1415.922]],\n",
              " ['That would give us a new expression, which we can', [1415.922, 1419.82]],\n",
              " ['maximize or minimize without thinking about', [1419.82, 1423.35]],\n",
              " ['the constraints anymore.', [1423.35, 1425.09]],\n",
              " [\"That's how Lagrange multipliers work.\", [1425.09, 1427.755]],\n",
              " ['So this brings us to miracle number four, developmental',\n",
              "  [1427.755, 1432.44]],\n",
              " ['piece number four.', [1432.44, 1433.77]],\n",
              " ['And it works like this.', [1433.77, 1436.42]],\n",
              " [\"We're going to say that L--\", [1436.42, 1438.21]],\n",
              " [\"the thing we're going to try to maximize in order to\", [1438.21, 1440.72]],\n",
              " ['maximize the width of the street--', [1440.72, 1442.66]],\n",
              " ['is equal to 1/2 times the magnitude of that vector, w,',\n",
              "  [1442.66, 1448.235]],\n",
              " ['squared minus.', [1448.235, 1452.476]],\n",
              " [\"And now, we've got to have a summation over all the\", [1452.476, 1456.23]],\n",
              " ['constraints.', [1456.23, 1457.48]],\n",
              " ['And each or those constraints is going to have a multiplier,',\n",
              "  [1458.88, 1461.46]],\n",
              " ['alpha sub i.', [1461.46, 1463.412]],\n",
              " ['And then, we write down the constraint.', [1463.412, 1466.106]],\n",
              " ['And when we write down a constraint,', [1466.106, 1467.575]],\n",
              " ['there it is up there.', [1467.575, 1469.1]],\n",
              " [\"And I've got to be hyper careful here, because,\", [1469.1, 1471.69]],\n",
              " [\"otherwise, I'll get lost in the algebra.\", [1471.69, 1473.83]],\n",
              " ['So the constraint is y sub i times vector, w, dotted with',\n",
              "  [1473.83, 1482.52]],\n",
              " [\"vector x sub i plus b, and now, I've got a closing\", [1482.52, 1489.03]],\n",
              " ['parenthesis, a minus 1.', [1489.03, 1492.315]],\n",
              " [\"That's the end of my constraint, like so.\", [1492.315, 1496.69]],\n",
              " [\"I sure hope I've got that right, because I'll be in deep\",\n",
              "  [1500.33, 1503.38]],\n",
              " [\"trouble if that's wrong.\", [1503.38, 1504.73]],\n",
              " ['Anybody see any bugs in that?', [1504.73, 1505.94]],\n",
              " [\"That looks right. doesn't it?\", [1505.94, 1508.25]],\n",
              " [\"We've got the original thing we're trying to work with.\",\n",
              "  [1508.25, 1510.31]],\n",
              " [\"Now, we've got Lagrange multipliers all multiplied.\", [1510.31, 1514.425]],\n",
              " [\"It's back to that constraint up there, where each\", [1514.425, 1516.3]],\n",
              " ['constraint is constrained to be 0.', [1516.3, 1520.512]],\n",
              " [\"Well, there's a little bit of mathematical slight of hand\",\n",
              "  [1520.512, 1524.77]],\n",
              " ['here, because in the end, the ones that are going to be 0,',\n",
              "  [1524.77, 1527.81]],\n",
              " ['the Lagrange multipliers here.', [1527.81, 1531.21]],\n",
              " ['The ones that are going to be non 0 are going to be the ones',\n",
              "  [1531.21, 1533.795]],\n",
              " ['connected with vectors that lie in the gutter.', [1533.795, 1536.12]],\n",
              " ['The rest are going to be 0.', [1536.12, 1539.848]],\n",
              " ['But in any event, we can pretend that this is what', [1539.848, 1543.38]],\n",
              " [\"we're doing.\", [1543.38, 1544.63]],\n",
              " [\"I don't care whether it's a maximum or minimum.\", [1546.55, 1548.35]],\n",
              " [\"I've lost track.\", [1548.35, 1549.55]],\n",
              " [\"But what we're going to do is we're going to try to find an\",\n",
              "  [1549.55, 1551.29]],\n",
              " ['extremum of that.', [1551.29, 1552.36]],\n",
              " ['So what do we do?', [1552.36, 1553.73]],\n",
              " ['What does 1801 teach us about?', [1553.73, 1558.33]],\n",
              " ['Finding the maximum--', [1558.33, 1559.465]],\n",
              " [\"well, we've got to find the derivatives and set them to 0.\",\n",
              "  [1559.465, 1564.76]],\n",
              " [\"And then, after we've done that, a little bit of that\", [1564.76, 1566.5]],\n",
              " [\"manipulation, we're going to see a wonderful\", [1566.5, 1568.76]],\n",
              " ['song start to emerge.', [1568.76, 1570.85]],\n",
              " [\"So let's see if we can do it.\", [1570.85, 1572.89]],\n",
              " [\"Let's take the partial of L, the Lagrangian, with respect\",\n",
              "  [1572.89, 1577.16]],\n",
              " ['to the vector, w.', [1577.16, 1579.19]],\n",
              " ['Oh my God, how do you differentiate with', [1579.19, 1581.43]],\n",
              " ['respect to a vector?', [1581.43, 1582.68]],\n",
              " ['It turns out that it has a form that looks exactly like',\n",
              "  [1585.255, 1588.05]],\n",
              " ['differentiating with respect to a scalar.', [1588.05, 1590.45]],\n",
              " ['And the way you prove that to yourself is you just expand',\n",
              "  [1590.45, 1592.58]],\n",
              " [\"everything in terms of all of the vector's components.\",\n",
              "  [1592.58, 1595.53]],\n",
              " [\"You differentiate those with respect to what you're\", [1595.53, 1597.66]],\n",
              " ['differentiating with respect to, and everything', [1597.66, 1600.14]],\n",
              " ['turns out the same.', [1600.14, 1602.38]],\n",
              " ['So what you get when you differentiate this with', [1602.38, 1604.88]],\n",
              " ['respect to the vector, w, is 2 comes down, and we have just',\n",
              "  [1604.88, 1612.28]],\n",
              " ['magnitude of w.', [1612.28, 1613.833]],\n",
              " ['Was it the magnitude of w?', [1613.833, 1616.09]],\n",
              " ['Yeah, like so.', [1616.09, 1618.0]],\n",
              " ['Was it the magnitude of w?', [1621.629, 1622.91]],\n",
              " [\"Oh, it's not the magnitude of w.\", [1622.91, 1626.51]],\n",
              " [\"It's just w, like so, no magnitude involved.\", [1626.51, 1632.396]],\n",
              " [\"Then, we've got a w over here, so we've got to differentiate\",\n",
              "  [1632.396, 1636.48]],\n",
              " ['this part with respect to w, as well.', [1636.48, 1638.27]],\n",
              " [\"But that part's a lot easier, because all we\", [1638.27, 1639.69]],\n",
              " ['have there is a w.', [1639.69, 1641.31]],\n",
              " [\"There's no magnitude.\", [1641.31, 1642.35]],\n",
              " [\"It's not raised to any power.\", [1642.35, 1644.002]],\n",
              " [\"So what's w multiplied by?\", [1644.002, 1646.29]],\n",
              " [\"Well, it's multiplied by x and y sub i and alpha sub i.\",\n",
              "  [1646.29, 1651.954]],\n",
              " ['All right.', [1651.954, 1652.61]],\n",
              " ['So that means that this expression, this derivative of',\n",
              "  [1652.61, 1656.605]],\n",
              " ['the Lagrangian, with respect to w is going to be equal to w',\n",
              "  [1656.605, 1661.66]],\n",
              " [\"minus the sum of alpha sub i, y sub i, x sub i, and that's\",\n",
              "  [1661.66, 1671.82]],\n",
              " ['got to be set to 0.', [1671.82, 1674.24]],\n",
              " ['And that implies that w is equal to the sum of some alpha',\n",
              "  [1674.24, 1682.25]],\n",
              " ['i, some scalars, times this minus 1 or plus 1 variable',\n",
              "  [1682.25, 1686.98]],\n",
              " ['times x sub i over i.', [1686.98, 1691.332]],\n",
              " ['And now, the math is beginning to sing.', [1691.332, 1694.43]],\n",
              " ['Because it tells us that the vector w is a linear sum of',\n",
              "  [1694.43, 1699.49]],\n",
              " ['the samples, all the samples or some of the sample.', [1699.49, 1704.492]],\n",
              " [\"It didn't have to be that way.\", [1704.492, 1707.786]],\n",
              " ['It could have been raised to a power.', [1707.786, 1709.23]],\n",
              " ['It could have been a logarithm.', [1709.23, 1711.16]],\n",
              " ['All sorts of horrible things could have', [1711.16, 1713.01]],\n",
              " ['happened when we did this.', [1713.01, 1714.32]],\n",
              " ['But when we did this, we discovered that w is going to',\n",
              "  [1714.32, 1719.21]],\n",
              " ['be equal to a linear some of these vectors here.', [1719.21, 1724.62]],\n",
              " ['Some of the vectors in the sample set, and I say some,',\n",
              "  [1724.62, 1729.06]],\n",
              " ['because for some alpha will be 0.', [1729.06, 1731.26]],\n",
              " ['All right.', [1734.265, 1735.515]],\n",
              " ['So this is something that we want to take note of as', [1735.515, 1741.56]],\n",
              " ['something important.', [1741.56, 1745.402]],\n",
              " [\"Now, of course, we've got to differentiate L with respect\",\n",
              "  [1745.402, 1749.76]],\n",
              " [\"to anything else it might vary, so we've got to\", [1749.76, 1752.9]],\n",
              " ['differentiate L with respect to b, as well.', [1752.9, 1755.18]],\n",
              " [\"So what's that going to be equal to?\", [1758.436, 1761.222]],\n",
              " [\"Well, there's no b in here, so that makes no contribution.\",\n",
              "  [1761.222, 1765.705]],\n",
              " [\"This part here doesn't have a b in it, so that makes no\",\n",
              "  [1765.705, 1768.75]],\n",
              " ['contribution.', [1768.75, 1769.335]],\n",
              " [\"There's no b over here, so that makes no contribution.\",\n",
              "  [1769.335, 1772.27]],\n",
              " [\"So we've got alpha i times y sub i times b.\", [1772.27, 1777.21]],\n",
              " ['That has a contribution.', [1777.21, 1779.365]],\n",
              " [\"So that's going to be the sum of alpha i times y sub i.\",\n",
              "  [1779.365, 1786.47]],\n",
              " [\"And then, we're differentiating with respect\", [1786.47, 1788.57]],\n",
              " ['to b, so that disappears.', [1788.57, 1790.635]],\n",
              " [\"There's a minus sign here, and that's equal to 0, or that\",\n",
              "  [1790.635, 1795.44]],\n",
              " ['implies that the sum of the alpha i times y sub', [1795.44, 1799.49]],\n",
              " ['i is equal to 0.', [1799.49, 1803.012]],\n",
              " ['Hm, that looks like that might be helpful somewhere.', [1803.012, 1805.1]],\n",
              " [\"And now, it's time for more coffee.\", [1810.46, 1812.755]],\n",
              " ['By the way, these coffee periods take months.', [1812.755, 1815.52]],\n",
              " ['You stare at it.', [1815.52, 1816.905]],\n",
              " ['You work on something else.', [1816.905, 1818.98]],\n",
              " [\"You've got to worry about your finals.\", [1818.98, 1822.0]],\n",
              " ['And you think about it some more.', [1822.0, 1824.02]],\n",
              " ['And eventually, you come back from coffee', [1824.02, 1825.74]],\n",
              " ['and do the next thing.', [1825.74, 1828.93]],\n",
              " ['Oh, what is the next thing?', [1828.93, 1831.64]],\n",
              " [\"Well, we've still got this expression that we're trying\",\n",
              "  [1831.64, 1834.18]],\n",
              " ['to find the minimum for.', [1834.18, 1841.02]],\n",
              " ['And you say to yourself, this is really a job for the', [1841.02, 1843.5]],\n",
              " ['numerical analysts.', [1843.5, 1844.48]],\n",
              " ['Those guys know about this sort of stuff.', [1844.48, 1847.205]],\n",
              " ['Because of that little power in there, that square.', [1847.205, 1849.62]],\n",
              " ['This is a so-called quadratic optimization problem.', [1849.62, 1854.772]],\n",
              " ['So at this point, you would be inclined to hand this problem',\n",
              "  [1854.772, 1857.48]],\n",
              " ['over to a numerical analysts.', [1857.48, 1859.29]],\n",
              " [\"They'll come back in a few weeks with an algorithm.\", [1859.29, 1861.41]],\n",
              " ['You implement the algorithm.', [1861.41, 1863.1]],\n",
              " ['And maybe things work.', [1863.1, 1864.12]],\n",
              " [\"Maybe they don't converge.\", [1864.12, 1864.89]],\n",
              " [\"But any case, you don't worry about it.\", [1864.89, 1868.325]],\n",
              " [\"But we're not going to do that, because we want to do a\",\n",
              "  [1868.325, 1870.36]],\n",
              " [\"little bit more math, because we're interested\", [1870.36, 1872.68]],\n",
              " ['in stuff like this.', [1872.68, 1874.89]],\n",
              " [\"We're interested in the fact that the decision vector is a\",\n",
              "  [1874.89, 1878.77]],\n",
              " ['linear sum of the samples.', [1878.77, 1881.265]],\n",
              " [\"So we're going to work a little harder on this stuff.\",\n",
              "  [1881.265, 1884.03]],\n",
              " [\"And in particular, now that we've got an expression for w,\",\n",
              "  [1884.03, 1887.73]],\n",
              " [\"this one right here, we're going to plug it back in\", [1887.73, 1891.01]],\n",
              " [\"there, and we're going to plug it back in here and see what\",\n",
              "  [1891.01, 1894.87]],\n",
              " [\"happens to that thing we're trying to find\", [1894.87, 1897.44]],\n",
              " ['the extremum of.', [1897.44, 1898.69]],\n",
              " ['Is everybody relaxed, taking deep breath?', [1906.817, 1911.22]],\n",
              " ['Actually, this is the easiest part.', [1911.22, 1912.53]],\n",
              " ['This is just doing a little bit of the algebra.', [1912.53, 1915.755]],\n",
              " [\"So the think we're trying to maximize or\", [1915.755, 1918.83]],\n",
              " ['minimize is equal to 1/2.', [1918.83, 1923.465]],\n",
              " [\"And now, we've got to have this vector\", [1923.465, 1930.57]],\n",
              " ['here in there twice.', [1930.57, 1936.781]],\n",
              " ['Right?', [1936.781, 1937.19]],\n",
              " [\"Because we're multiplying the two together.\", [1937.19, 1941.295]],\n",
              " [\"So let's see.\", [1941.295, 1942.97]],\n",
              " [\"We've got from that expression up there, one of those w's\",\n",
              "  [1942.97, 1946.86]],\n",
              " ['will just be the sum of the alpha i times y sub i times',\n",
              "  [1946.86, 1953.67]],\n",
              " ['the vector x sub i.', [1953.67, 1956.265]],\n",
              " [\"And then, we've got the other one, too.\", [1956.265, 1958.32]],\n",
              " [\"So that's just going to be the sum of alpha.\", [1958.32, 1961.62]],\n",
              " [\"Now, I'm going to, actually, eventually, squish those two\",\n",
              "  [1961.62, 1965.28]],\n",
              " ['sums together into a double summation, so I have to keep',\n",
              "  [1965.28, 1968.05]],\n",
              " ['the indexes straight.', [1968.05, 1969.99]],\n",
              " [\"So I'm just going to write that as alpha sub j, y\", [1969.99, 1973.786]],\n",
              " ['sub j, x sub j.', [1973.786, 1977.726]],\n",
              " [\"So those are my two vectors and I'm going to take the dot\",\n",
              "  [1977.726, 1979.76]],\n",
              " ['product of those.', [1979.76, 1980.85]],\n",
              " [\"That's the first piece, right?\", [1980.85, 1984.31]],\n",
              " ['Boy, this is hard.', [1984.31, 1987.345]],\n",
              " ['So minus, and now, the next term looks like alpha i, y sub',\n",
              "  [1987.345, 1993.76]],\n",
              " ['i, x sub i times w.', [1993.76, 1997.395]],\n",
              " [\"So you've got a whole bunch of these.\", [1997.395, 1999.64]],\n",
              " [\"We've got a sum of alpha i times y sub i times x sub i,\",\n",
              "  [1999.64, 2006.996]],\n",
              " ['and then, that gets multiplied times w.', [2006.996, 2010.425]],\n",
              " [\"So we'll put this like this, the sum of alpha j, y sub j, x\",\n",
              "  [2010.425, 2019.16]],\n",
              " ['sub j in there like that.', [2019.16, 2021.63]],\n",
              " [\"And then, that's the dot product like that.\", [2021.63, 2024.345]],\n",
              " [\"That wasn't as bad as I thought.\", [2024.345, 2025.89]],\n",
              " [\"Now, I've got to deal with the next term, the alpha i times y\",\n",
              "  [2029.731, 2034.15]],\n",
              " ['sub i times b.', [2034.15, 2035.74]],\n",
              " [\"So that's minus sub of alpha i times y sub i times b.\",\n",
              "  [2038.475, 2047.746]],\n",
              " ['And then, to finish it off, we have plus the sum of alpha sub',\n",
              "  [2047.746, 2053.949]],\n",
              " ['i minus 1 up there, minus 1 in front of the summation, such',\n",
              "  [2053.949, 2058.32]],\n",
              " ['as the sum of the alphas.', [2058.32, 2060.059]],\n",
              " ['Are you with me so far?', [2060.059, 2061.605]],\n",
              " ['Just a little algebra.', [2061.605, 2064.096]],\n",
              " ['It looks good.', [2064.096, 2064.86]],\n",
              " [\"I think I haven't mucked it, yet.\", [2064.86, 2068.838]],\n",
              " [\"Let's see.\", [2068.838, 2070.952]],\n",
              " ['alpha i times y sub i times b. b is a constant.', [2070.952, 2074.365]],\n",
              " ['So pull that out there, and then, I just got the sum of',\n",
              "  [2074.365, 2077.41]],\n",
              " ['alpha sub i times y sub i.', [2077.41, 2081.078]],\n",
              " [\"Oh, that's good.\", [2081.078, 2082.25]],\n",
              " [\"That's 0.\", [2082.25, 2083.5]],\n",
              " ['Now, so for every one of these terms, we dot it with this',\n",
              "  [2088.305, 2091.9]],\n",
              " ['whole expression.', [2091.9, 2093.15]],\n",
              " [\"So that's just like taking this thing here and dotting\",\n",
              "  [2094.966, 2100.05]],\n",
              " ['those two things together, right?', [2100.05, 2102.145]],\n",
              " [\"Oh, but that's just the same thing we've got here.\", [2102.145, 2104.24]],\n",
              " ['So now, what we can do is we can say that we can rewrite',\n",
              "  [2107.324, 2111.14]],\n",
              " ['this Lagrangian as--', [2111.14, 2115.56]],\n",
              " [\"we've got that sum of alpha i.\", [2115.56, 2119.566]],\n",
              " [\"That's the positive element.\", [2119.566, 2122.256]],\n",
              " [\"And then, we've got one of these and half of these.\", [2122.256, 2125.68]],\n",
              " [\"So that's minus 1/2.\", [2125.68, 2128.865]],\n",
              " [\"And now, I'll just convert that whole works into a double\",\n",
              "  [2128.865, 2130.98]],\n",
              " ['sum over both i and j of alpha i times alpha j times y sub i',\n",
              "  [2130.98, 2143.23]],\n",
              " ['times y sub j times x sub i dotted with x of j.', [2143.23, 2149.76]],\n",
              " ['We sure went through a lot of trouble to get there, but now,',\n",
              "  [2152.67, 2155.56]],\n",
              " [\"we've got it.\", [2155.56, 2156.21]],\n",
              " [\"And we know that what we're trying to do is we're trying\",\n",
              "  [2156.21, 2159.2]],\n",
              " ['to find a maximum of that expression.', [2159.2, 2163.32]],\n",
              " [\"And that's the one we're going to had off to\", [2167.212, 2168.91]],\n",
              " ['the numerical analysts.', [2168.91, 2171.01]],\n",
              " [\"So if we're going to had this off to the numerical analysts\",\n",
              "  [2171.01, 2173.09]],\n",
              " ['anyway, why did I go to all this trouble?', [2173.09, 2176.136]],\n",
              " ['Good question.', [2176.136, 2179.2]],\n",
              " ['Do you have any idea why I went to all this trouble?', [2179.2, 2182.626]],\n",
              " ['Because I wanted to find out the dependence of this', [2182.626, 2185.44]],\n",
              " ['expression.', [2185.44, 2186.95]],\n",
              " ['Wanda is telling me.', [2186.95, 2188.12]],\n",
              " [\"I'm translating as I go.\", [2188.12, 2189.45]],\n",
              " [\"She's telling me in Romanian.\", [2189.45, 2191.555]],\n",
              " ['I want to find what this maximization depends on with',\n",
              "  [2191.555, 2195.51]],\n",
              " ['respect these vectors, the x, the sample vectors.', [2195.51, 2201.16]],\n",
              " [\"And what I've discovered is that the optimization depends\",\n",
              "  [2201.16, 2206.48]],\n",
              " ['only on the dot product of pairs of samples.', [2206.48, 2213.976]],\n",
              " [\"And that's something we want to keep in mind.\", [2213.976, 2215.3]],\n",
              " [\"That's why I put it in royal purple.\", [2215.3, 2216.62]],\n",
              " [\"Now, up here, so let's see.\", [2219.35, 2222.92]],\n",
              " ['What do we call that one up there?', [2222.92, 2224.21]],\n",
              " [\"That's two.\", [2224.21, 2225.715]],\n",
              " [\"I guess, we'll call this piece here three.\", [2225.715, 2230.505]],\n",
              " ['This piece here is four.', [2230.505, 2232.6]],\n",
              " [\"And now, there's one more piece.\", [2232.6, 2235.06]],\n",
              " ['Because I want to take that w, and not only stick it back',\n",
              "  [2235.06, 2240.08]],\n",
              " ['into that Lagrangian, I want to stick it back into the', [2240.08, 2242.7]],\n",
              " ['decision rule.', [2242.7, 2244.446]],\n",
              " ['So now, my decision rule with this expression for w is going',\n",
              "  [2244.446, 2249.03]],\n",
              " ['to be w plugged into that thing.', [2249.03, 2251.41]],\n",
              " ['So the decision rule is going to look like the sum of alpha',\n",
              "  [2251.41, 2257.0]],\n",
              " ['i times y sub i times x sub i dotted with the unknown', [2257.0, 2265.96]],\n",
              " ['vector, like so.', [2265.96, 2267.84]],\n",
              " [\"And we're going to, I guess, add b.\", [2267.84, 2271.536]],\n",
              " [\"And we're going to say, if that's greater than or equal\",\n",
              "  [2271.536, 2273.77]],\n",
              " ['to 0, then plus.', [2273.77, 2277.66]],\n",
              " ['So you see why the math is beginning to sing to us now.',\n",
              "  [2280.56, 2284.75]],\n",
              " ['Because now, we discover that the decision rule, also,',\n",
              "  [2284.75, 2288.84]],\n",
              " ['depends only on the dot product of those sample', [2288.84, 2292.7]],\n",
              " ['vectors and the unknown.', [2292.7, 2295.34]],\n",
              " ['So the total of dependence of all of the', [2295.34, 2298.64]],\n",
              " ['math on the dot products.', [2298.64, 2301.106]],\n",
              " ['All right.', [2301.106, 2304.034]],\n",
              " ['And now, I hear a whisper.', [2304.034, 2307.16]],\n",
              " [\"Someone is saying, I don't believe that\", [2307.16, 2310.41]],\n",
              " ['mathematicians can do it.', [2310.41, 2311.72]],\n",
              " [\"I don't think those numerical analysts can find the\", [2311.72, 2313.85]],\n",
              " ['optimization.', [2313.85, 2315.1]],\n",
              " ['I want to be sure of it.', [2317.36, 2318.925]],\n",
              " ['Give me ocular proof.', [2318.925, 2320.85]],\n",
              " [\"So I'd like to run a demonstration of it.\", [2320.85, 2322.36]],\n",
              " ['OK.', [2336.596, 2337.09]],\n",
              " [\"There's our sample problem.\", [2337.09, 2338.06]],\n",
              " ['The one I started the hour out with.', [2338.06, 2339.8]],\n",
              " [\"Now, if the optimization algorithm doesn't get stuck in\",\n",
              "  [2339.8, 2345.43]],\n",
              " ['a local maximum or something, it should find a nice,', [2345.43, 2347.72]],\n",
              " ['straight line separating those two guys to finding the widest',\n",
              "  [2347.72, 2350.9]],\n",
              " ['street between the minuses and the pluses.', [2350.9, 2354.445]],\n",
              " ['So in just a couple of steps, you can see down', [2354.445, 2356.88]],\n",
              " ['there in step 11.', [2356.88, 2358.15]],\n",
              " [\"It's decided that it's done as much as it can on the\", [2358.15, 2360.63]],\n",
              " ['optimization.', [2360.63, 2362.406]],\n",
              " [\"And it's got three alphas.\", [2362.406, 2365.48]],\n",
              " ['And you can see that the two negative samples both figure',\n",
              "  [2365.48, 2370.97]],\n",
              " ['into the solution, the weights on the Lagrangian multipliers',\n",
              "  [2370.97, 2374.575]],\n",
              " ['are given by those little yellow bars.', [2374.575, 2376.82]],\n",
              " ['So the two negatives participate in the solution as', [2376.82, 2380.03]],\n",
              " [\"one of the positives, but the other positive doesn't.\", [2380.03, 2382.04]],\n",
              " ['So it has a 0 weight.', [2382.04, 2385.5]],\n",
              " ['So everything worked out well.', [2385.5, 2387.7]],\n",
              " [\"Now, I said, as long as it doesn't get stuck on a local\",\n",
              "  [2387.7, 2390.44]],\n",
              " ['maximum, guess what, those mathematical friends of ours',\n",
              "  [2390.44, 2395.095]],\n",
              " ['can tell us and prove to us that this', [2395.095, 2398.12]],\n",
              " ['thing is a convex space.', [2398.12, 2400.42]],\n",
              " ['That means it can never get stuck in a local maximum.',\n",
              "  [2400.42, 2404.042]],\n",
              " ['So in contrast with things like neural nets, where you',\n",
              "  [2404.042, 2407.78]],\n",
              " ['have a plague of local maxima, this guy never gets stuck in a',\n",
              "  [2407.78, 2411.16]],\n",
              " ['local maxima.', [2411.16, 2412.355]],\n",
              " [\"Let's try some other examples.\", [2412.355, 2415.536]],\n",
              " [\"Here's two vertical points--\", [2415.536, 2417.25]],\n",
              " ['no surprises there, right?', [2417.25, 2420.92]],\n",
              " [\"Well, you say, well, maybe it can't deal\", [2420.92, 2422.47]],\n",
              " ['with diagonal points.', [2422.47, 2424.165]],\n",
              " ['Sure it can.', [2424.165, 2426.83]],\n",
              " ['How about this thing here?', [2426.83, 2432.091]],\n",
              " ['Yeah, it only needed two of the points since any two, a',\n",
              "  [2432.091, 2438.51]],\n",
              " ['plus or minus, will define the street.', [2438.51, 2441.82]],\n",
              " [\"Let's try this guy.\", [2441.82, 2444.58]],\n",
              " ['Oh.', [2444.58, 2446.526]],\n",
              " ['What do you think?', [2446.526, 2447.11]],\n",
              " ['What happened here?', [2447.11, 2450.046]],\n",
              " [\"Well, we're screwed, right?\", [2450.046, 2451.345]],\n",
              " [\"Because it's linearly inseparable--\", [2451.345, 2452.595]],\n",
              " ['bad news.', [2456.629, 2457.879]],\n",
              " [\"So in situations where it's linearly inseparable, the\",\n",
              "  [2460.175, 2464.25]],\n",
              " ['mechanism struggles, and eventually, it will just slow',\n",
              "  [2464.25, 2467.06]],\n",
              " [\"down and you truncate it, because it's\", [2467.06, 2468.57]],\n",
              " ['not making any progress.', [2468.57, 2469.51]],\n",
              " ['And you see the red dots there are ones that it got wrong.',\n",
              "  [2469.51, 2474.765]],\n",
              " [\"So you say, well, too bad for our side-- doesn't look like\",\n",
              "  [2474.765, 2477.48]],\n",
              " [\"it's all that good anyway.\", [2477.48, 2479.502]],\n",
              " ['But then, a powerful idea comes to the rescue, when', [2479.502, 2486.02]],\n",
              " ['stuck switch to another perspective.', [2486.02, 2488.896]],\n",
              " [\"So if we don't like the space that we're in, because it\",\n",
              "  [2488.896, 2491.85]],\n",
              " ['gives examples that are not linearly separable, then we',\n",
              "  [2491.85, 2497.68]],\n",
              " ['can say, oh, shoot.', [2497.68, 2499.705]],\n",
              " [\"Here's our space.\", [2499.705, 2502.052]],\n",
              " ['Here are two points.', [2502.052, 2503.302]],\n",
              " ['Here are two other points.', [2509.486, 2512.944]],\n",
              " [\"We can't separate them.\", [2512.944, 2514.63]],\n",
              " ['But if we could somehow get them into another space, maybe',\n",
              "  [2514.63, 2517.74]],\n",
              " ['we can separate them, because they look like this in the',\n",
              "  [2517.74, 2526.6]],\n",
              " [\"other space, and they're easy to separate.\", [2526.6, 2528.925]],\n",
              " ['So what we need, then, is a transformation that will take',\n",
              "  [2528.925, 2532.82]],\n",
              " [\"us from the space we're in into a space where things are\",\n",
              "  [2532.82, 2536.07]],\n",
              " [\"more convenient, so we're going to call that\", [2536.07, 2537.59]],\n",
              " ['transformation phi with a vector, x.', [2537.59, 2542.745]],\n",
              " [\"That's the transformation.\", [2542.745, 2543.855]],\n",
              " [\"And now, here's the reason for all the magic.\", [2543.855, 2546.29]],\n",
              " ['I said, that the maximization only depends on dot products.',\n",
              "  [2548.95, 2554.88]],\n",
              " ['So all I need to do the maximization is the', [2554.88, 2558.81]],\n",
              " ['transformation of one vector dotted with the transformation',\n",
              "  [2558.81, 2563.975]],\n",
              " ['of another vector, like so.', [2563.975, 2567.235]],\n",
              " [\"That's what I need to maximize, or to find the\", [2567.235, 2571.26]],\n",
              " ['maximum on.', [2571.26, 2572.51]],\n",
              " ['Then, in order to recognize--', [2572.51, 2575.216]],\n",
              " ['where did it go?', [2575.216, 2577.706]],\n",
              " ['Underneath the chalkboard.', [2577.706, 2579.26]],\n",
              " ['Oh, yes.', [2585.29, 2586.002]],\n",
              " ['Here it is.', [2586.002, 2586.9]],\n",
              " ['To recognize, all I need is dot products, too.', [2586.9, 2589.62]],\n",
              " ['So for that one I need phi of x dotted with phi of u.',\n",
              "  [2589.62, 2597.025]],\n",
              " ['And just to make this a little bit more consistent, the',\n",
              "  [2597.025, 2599.3]],\n",
              " [\"notation, I'll call that x j and this x sub i.\", [2599.3, 2602.75]],\n",
              " [\"And that's x sub i.\", [2602.75, 2603.55]],\n",
              " ['Those are the quantities I need in order to do it.', [2603.55, 2607.595]],\n",
              " [\"So that means that if I have a function, let's call it k of x\",\n",
              "  [2607.595, 2614.54]],\n",
              " [\"sub i and x sub j, that's equal to phi of x sub i dotted\",\n",
              "  [2614.54, 2625.37]],\n",
              " ['with phi of x sub j.', [2625.37, 2629.191]],\n",
              " [\"Then, I'm done.\", [2629.191, 2630.215]],\n",
              " ['This is what I need.', [2630.215, 2632.306]],\n",
              " [\"I don't actually need this.\", [2632.306, 2634.02]],\n",
              " ['All I need is that function, k, which happens to be called',\n",
              "  [2636.955, 2640.99]],\n",
              " ['a kernel function, which provides me with the dot', [2640.99, 2644.65]],\n",
              " ['product of those two vectors in another space.', [2644.65, 2647.745]],\n",
              " [\"I don't have to know the transformation\", [2647.745, 2649.31]],\n",
              " ['into the other space.', [2649.31, 2651.2]],\n",
              " [\"And that's the reason that this stuff is a miracle.\", [2651.2, 2655.935]],\n",
              " ['So what are some of the kernels that are popular?', [2655.935, 2659.595]],\n",
              " ['One is the linear kernel that says that u dotted with v plus',\n",
              "  [2659.595, 2667.2]],\n",
              " [\"1 to the n-th is such a kernel, because it's got u in\", [2667.2, 2672.515]],\n",
              " ['it and v in it, the two vectors.', [2672.515, 2675.19]],\n",
              " ['And this is what the dot product is in the other space.',\n",
              "  [2675.19, 2678.06]],\n",
              " [\"So that's one choice.\", [2678.06, 2679.55]],\n",
              " ['Another choice is a kernel that looks like', [2679.55, 2682.45]],\n",
              " ['this, e to the minus.', [2682.45, 2686.295]],\n",
              " [\"Let's take the dot product of the difference\", [2686.295, 2690.44]],\n",
              " ['of those two guys.', [2690.44, 2691.69]],\n",
              " [\"Let's take the magnitude of that and\", [2693.88, 2696.36]],\n",
              " ['divide it by some sigma.', [2696.36, 2697.66]],\n",
              " [\"That's a second kind of kernel that we can use.\", [2697.66, 2701.16]],\n",
              " [\"So let's go back and see if we can solve this problem by\",\n",
              "  [2701.16, 2704.35]],\n",
              " ['transforming it into another space where we have another',\n",
              "  [2704.35, 2706.35]],\n",
              " ['perspective.', [2706.35, 2707.6]],\n",
              " [\"So that's it.\", [2710.082, 2715.618]],\n",
              " [\"That's another kernel.\", [2715.618, 2717.76]],\n",
              " ['And so sure, we can.', [2717.76, 2718.87]],\n",
              " [\"And that's the answer when transformed back into the\", [2718.87, 2721.28]],\n",
              " ['original space.', [2721.28, 2722.905]],\n",
              " ['We can also try doing that with a so-called', [2722.905, 2724.69]],\n",
              " ['radial basis kernel.', [2724.69, 2725.78]],\n",
              " [\"That's the one with the exponential in it.\", [2725.78, 2728.112]],\n",
              " ['We can learn on that one.', [2728.112, 2729.31]],\n",
              " ['Boom.', [2729.31, 2730.48]],\n",
              " ['No problem.', [2730.48, 2733.346]],\n",
              " [\"So we've got a general method that's convex and guaranteed\",\n",
              "  [2733.346, 2736.86]],\n",
              " ['to produce a global solution.', [2736.86, 2739.245]],\n",
              " [\"We've got a mechanism that easily allows us to transform\",\n",
              "  [2739.245, 2742.95]],\n",
              " ['this into another space.', [2742.95, 2745.47]],\n",
              " ['So it works like a charm.', [2745.47, 2747.695]],\n",
              " [\"Of course, it doesn't remove all possible problems.\", [2747.695, 2750.736]],\n",
              " ['Look at that exponential thing here.', [2750.736, 2753.65]],\n",
              " ['If we choose a sigma that is small enough, then those', [2753.65, 2759.89]],\n",
              " ['sigmas are essentially shrunk right around the sample', [2759.89, 2762.76]],\n",
              " ['points, and we could get overfitting.', [2762.76, 2766.092]],\n",
              " [\"So it doesn't immunize us against overfitting, but it\",\n",
              "  [2766.092, 2769.385]],\n",
              " ['does immunize us against local maxima and does provide us',\n",
              "  [2769.385, 2772.5]],\n",
              " ['with a general mechanism for doing a transformation into',\n",
              "  [2772.5, 2776.82]],\n",
              " ['another space with a better perspective.', [2776.82, 2778.935]],\n",
              " ['Now, the history lesson, all this stuff feels fairly new.',\n",
              "  [2778.935, 2782.435]],\n",
              " [\"It feels like it's younger than you are.\", [2782.435, 2785.746]],\n",
              " [\"Here's the history of it.\", [2785.746, 2787.822]],\n",
              " ['Vapnik immigrated from the Soviet Union to the United',\n",
              "  [2787.822, 2791.06]],\n",
              " ['States in about 1991.', [2791.06, 2793.76]],\n",
              " ['Nobody ever heard of this stuff before he immigrated.',\n",
              "  [2793.76, 2796.795]],\n",
              " ['He actually had done this work on the basic support vector',\n",
              "  [2796.795, 2800.2]],\n",
              " ['idea in his Ph.D. thesis at Moscow University', [2800.2, 2804.355]],\n",
              " [\"in the early '60s.\", [2804.355, 2806.59]],\n",
              " [\"But it wasn't possible for him to do anything with it,\",\n",
              "  [2806.59, 2809.47]],\n",
              " [\"because they didn't have any computers they could try\", [2809.47, 2811.22]],\n",
              " ['anything out with.', [2811.22, 2813.01]],\n",
              " ['So he spent the next 25 years at some oncology institute in',\n",
              "  [2813.01, 2817.46]],\n",
              " ['the Soviet Union doing applications.', [2817.46, 2820.66]],\n",
              " ['Somebody from Bell Labs discovers him, invites him', [2820.66, 2823.44]],\n",
              " ['over to the United States where, subsequently, he', [2823.44, 2825.445]],\n",
              " ['decides to immigrate.', [2825.445, 2827.466]],\n",
              " ['In 1992, or thereabouts, Vapnik submits three papers to',\n",
              "  [2827.466, 2833.58]],\n",
              " ['NIPS, the Neural Information Processing Systems journal.',\n",
              "  [2833.58, 2837.115]],\n",
              " ['All of them were rejected.', [2837.115, 2839.065]],\n",
              " [\"He's still sore about it, but it's motivating.\", [2839.065, 2843.57]],\n",
              " ['So around 1992, 1993, Bell Labs was interested in', [2843.57, 2847.06]],\n",
              " ['hand-written character recognition', [2847.06, 2848.42]],\n",
              " ['and in neural nets.', [2848.42, 2850.456]],\n",
              " ['Vapnik thinks that neural nets--', [2850.456, 2853.27]],\n",
              " ['what would be a good word to use?', [2853.27, 2856.295]],\n",
              " ['I can think of the vernacular, but he thinks that', [2856.295, 2858.41]],\n",
              " [\"they're not very good.\", [2858.41, 2860.15]],\n",
              " ['So he bets a colleague a good dinner that support vector',\n",
              "  [2860.15, 2864.32]],\n",
              " ['machines will eventually do better at handwriting', [2864.32, 2866.385]],\n",
              " ['recognition then neural nets.', [2866.385, 2870.356]],\n",
              " [\"And it's a dinner bet, right?\", [2870.356, 2871.69]],\n",
              " [\"It's not that big of deal.\", [2871.69, 2872.6]],\n",
              " [\"But as Napoleon said, it's amazing what a soldier will do\",\n",
              "  [2872.6, 2875.28]],\n",
              " ['for a bit of ribbon.', [2875.28, 2877.641]],\n",
              " [\"So that makes colleague, who's working on this problem with\",\n",
              "  [2877.641, 2881.38]],\n",
              " ['handwritten recognition, decides to try a support', [2881.38, 2886.73]],\n",
              " ['vector machine with a kernel, in which n equals 2, just',\n",
              "  [2886.73, 2892.7]],\n",
              " ['slightly nonlinear, works like a charm.', [2892.7, 2894.82]],\n",
              " ['Was this the first time anybody tried a kernel?', [2897.53, 2899.89]],\n",
              " ['Vapnik actually had the idea in his thesis but never though',\n",
              "  [2899.89, 2903.07]],\n",
              " ['it was very important.', [2903.07, 2905.56]],\n",
              " [\"As soon as it was shown to work in the early '90s on the\",\n",
              "  [2905.56, 2909.67]],\n",
              " ['problem handwriting recognition, Vapnik', [2909.67, 2912.09]],\n",
              " ['resuscitated the idea of the kernel, began to develop it,',\n",
              "  [2912.09, 2915.19]],\n",
              " ['and became an essential part of the whole approach of using',\n",
              "  [2915.19, 2918.27]],\n",
              " ['support vector machines.', [2918.27, 2919.92]],\n",
              " ['So the main point about this is that it was 30 years in',\n",
              "  [2919.92, 2923.98]],\n",
              " ['between the concept and anybody ever hearing about it.',\n",
              "  [2923.98, 2927.38]],\n",
              " [\"It was 30 years between Vapnik's understanding of\", [2927.38, 2932.36]],\n",
              " ['kernels and his appreciation of their importance.', [2932.36, 2935.84]],\n",
              " [\"And that's the way things often go, great ideas followed\",\n",
              "  [2935.84, 2939.87]],\n",
              " ['by long periods of nothing happening, followed by an', [2939.87, 2943.32]],\n",
              " ['epiphanous moment when the original idea seemed to have',\n",
              "  [2943.32, 2946.64]],\n",
              " ['great power with just a little bit of a twist.', [2946.64, 2949.32]],\n",
              " ['And then, the world never looks back.', [2949.32, 2950.96]],\n",
              " [\"And Vapnik, who nobody ever heard of until the early '90s,\",\n",
              "  [2950.96, 2954.78]],\n",
              " ['becomes famous for something that everybody knows about',\n",
              "  [2954.78, 2958.38]],\n",
              " ['today who does machine learning.', [2958.38, 2959.63]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nFOcMl8pKIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Speech Recognition Code to enable microphone\n",
        "\n",
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import io\n",
        "import ffmpeg\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };            \n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {            \n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data); \n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      //console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "\n",
        "recordButton.innerText = \"Recording... press to stop\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
        "  }\n",
        "}\n",
        "\n",
        "// https://stackoverflow.com/a/951057\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "//recordButton.addEventListener(\"click\", toggleRecording);\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "\n",
        "sleep(2000).then(() => {\n",
        "  // wait 2000ms for the data to be available...\n",
        "  // ideally this should use something like await...\n",
        "  //console.log(\"Inside data:\" + base64data)\n",
        "  resolve(base64data.toString())\n",
        "\n",
        "});\n",
        "\n",
        "}\n",
        "});\n",
        "      \n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  \n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "  \n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  return audio, sr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfvueipypTo9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "ac3735b7-c59e-4671-c12e-0debb71b2e55"
      },
      "source": [
        "#Speech to Text conversion to obtain the voice query as text\n",
        "\n",
        "text=0\n",
        "import speech_recognition\n",
        "r = speech_recognition.Recognizer()\n",
        "print(\"Speak Anything :\")\n",
        "audio, sr = get_audio()\n",
        "#print(type(audio))\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "\n",
        "write('test.wav', 44100, audio)\n",
        "with speech_recognition.AudioFile('test.wav') as source:\n",
        "        audio = r.record(source)  # read the entire audio file                  \n",
        "        try:\n",
        "            text = r.recognize_google(audio)\n",
        "            print(\"You said : {}\".format(text))\n",
        "        except:\n",
        "            print(\"Sorry could not recognize what you said\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Speak Anything :\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_p = document.createElement(\"P\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var t = document.createTextNode(\"Press to start recording\");\n",
              "\n",
              "my_btn.appendChild(t);\n",
              "//my_p.appendChild(my_btn);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var reader;\n",
              "var recorder, gumStream;\n",
              "var recordButton = my_btn;\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  var options = {\n",
              "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
              "    mimeType : 'audio/webm;codecs=opus'\n",
              "    //mimeType : 'audio/webm;codecs=pcm'\n",
              "  };            \n",
              "  //recorder = new MediaRecorder(stream, options);\n",
              "  recorder = new MediaRecorder(stream);\n",
              "  recorder.ondataavailable = function(e) {            \n",
              "    var url = URL.createObjectURL(e.data);\n",
              "    var preview = document.createElement('audio');\n",
              "    preview.controls = true;\n",
              "    preview.src = url;\n",
              "    document.body.appendChild(preview);\n",
              "\n",
              "    reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data); \n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "      //console.log(\"Inside FileReader:\" + base64data);\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "  };\n",
              "\n",
              "recordButton.innerText = \"Recording... press to stop\";\n",
              "\n",
              "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "\n",
              "function toggleRecording() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
              "  }\n",
              "}\n",
              "\n",
              "// https://stackoverflow.com/a/951057\n",
              "function sleep(ms) {\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "//recordButton.addEventListener(\"click\", toggleRecording);\n",
              "recordButton.onclick = ()=>{\n",
              "toggleRecording()\n",
              "\n",
              "sleep(2000).then(() => {\n",
              "  // wait 2000ms for the data to be available...\n",
              "  // ideally this should use something like await...\n",
              "  //console.log(\"Inside data:\" + base64data)\n",
              "  resolve(base64data.toString())\n",
              "\n",
              "});\n",
              "\n",
              "}\n",
              "});\n",
              "      \n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "You said : contain\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DE99Cij87xy0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "86a57eb7-ff3e-4dbd-8281-50b41d4c902a"
      },
      "source": [
        "#Mounting Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyAnnJy9s-R6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text=\"constraint\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1Yqd7lVtAcP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c7cba00b-af3d-4d01-ab91-3b7952c1ee37"
      },
      "source": [
        "#Processing the transcripts to generate the final video segments according to the voice query given by the user\n",
        "#Cutting threshold - 2(represented by variable c)\n",
        "\n",
        "final=[]\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "c=0\n",
        "i= 0\n",
        "#name=\"videoplayback.mp4\"\n",
        "while(i<len(transcript)):\n",
        "  print(transcript[i][0])\n",
        "  f=open(\"drive/My Drive/Mini-Project/audio1.txt\",'w')\n",
        "  f.write('i = '+str(i)+\"\\nfinal = \"+str(final)+\"\\n\")\n",
        "  f.close()\n",
        "  if(text in transcript[i][0] or semantic_similarity(transcript[i][0],text)>=0.6):\n",
        "    c=0\n",
        "    j=i+1\n",
        "    k=i\n",
        "    start=transcript[i][1][0]\n",
        "    end=transcript[i][1][1]\n",
        "    while(j<len(transcript)):\n",
        "      if(semantic_similarity(transcript[j][0],transcript[k][0])>=0.5):\n",
        "        k=j\n",
        "        c=0\n",
        "        end=transcript[j][1][1]\n",
        "      else:\n",
        "        c+=1\n",
        "        if(c>=2):\n",
        "          final.append([transcript[i][0],[start,end]])\n",
        "          i=j\n",
        "          break\n",
        "      j+=1\n",
        "    print(\"match\")\n",
        "    print(final)\n",
        "  i+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "another space with a better perspective.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, the history lesson, all this stuff feels fairly new.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "It feels like it's younger than you are.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Here's the history of it.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Vapnik immigrated from the Soviet Union to the United\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "States in about 1991.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Nobody ever heard of this stuff before he immigrated.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "He actually had done this work on the basic support vector\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "idea in his Ph.D. thesis at Moscow University\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "in the early '60s.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "But it wasn't possible for him to do anything with it,\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "because they didn't have any computers they could try\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "anything out with.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "So he spent the next 25 years at some oncology institute in\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the Soviet Union doing applications.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Somebody from Bell Labs discovers him, invites him\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "over to the United States where, subsequently, he\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "decides to immigrate.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "In 1992, or thereabouts, Vapnik submits three papers to\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NIPS, the Neural Information Processing Systems journal.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All of them were rejected.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "He's still sore about it, but it's motivating.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "So around 1992, 1993, Bell Labs was interested in\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "hand-written character recognition\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "and in neural nets.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Vapnik thinks that neural nets--\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "what would be a good word to use?\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "I can think of the vernacular, but he thinks that\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "they're not very good.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "So he bets a colleague a good dinner that support vector\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "machines will eventually do better at handwriting\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "recognition then neural nets.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "And it's a dinner bet, right?\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "It's not that big of deal.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "But as Napoleon said, it's amazing what a soldier will do\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "for a bit of ribbon.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "So that makes colleague, who's working on this problem with\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "handwritten recognition, decides to try a support\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "vector machine with a kernel, in which n equals 2, just\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "slightly nonlinear, works like a charm.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Was this the first time anybody tried a kernel?\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Vapnik actually had the idea in his thesis but never though\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it was very important.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "As soon as it was shown to work in the early '90s on the\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "problem handwriting recognition, Vapnik\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "resuscitated the idea of the kernel, began to develop it,\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "and became an essential part of the whole approach of using\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "support vector machines.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "So the main point about this is that it was 30 years in\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "between the concept and anybody ever hearing about it.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "It was 30 years between Vapnik's understanding of\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "kernels and his appreciation of their importance.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "And that's the way things often go, great ideas followed\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "by long periods of nothing happening, followed by an\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epiphanous moment when the original idea seemed to have\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "great power with just a little bit of a twist.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "And then, the world never looks back.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "And Vapnik, who nobody ever heard of until the early '90s,\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "becomes famous for something that everybody knows about\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "today who does machine learning.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3E1UCuAnhKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Final List generated\n",
        "\n",
        "final = [[\"So we don't have enough constraint here to fix a\", [462.74, 465.75]], [\"additional constraints whether you're toward putting enough\", [485.79, 493.33]], ['to be equal to or greater than 1.', [530.05, 531.37]], ['that this decision function gives the', [546.12, 548.55]], [\"going to add the additional constraint that it's going to\", [831.14, 833.54]], ['some constraints.', [874.34, 876.416]], ['equation that constrains the samples', [1045.954, 1055.61]], ['Well, I decided I was going to enforce this constraint.', [1134.21, 1139.27]], ['Then, I used the constraint to plug back some values here.', [1146.105, 1149.4]], ['minimum of, the extremum of.', [1355.68, 1358.236]], [\"a function with constraints, then we're going to have to\", [1408.462, 1415.922]], ['the constraints anymore.', [1423.35, 1425.09]], ['constraints.', [1456.23, 1457.48]], ['And then, we write down the constraint.', [1463.412, 1467.575]], ['So the constraint is y sub i times vector, w, dotted with', [1473.83, 1489.03]], [\"It's back to that constraint up there, where each\", [1514.425, 1516.3]], ['Finding the maximum--', [1558.33, 1564.76]], [\"Let's take the partial of L, the Lagrangian, with respect\", [1572.89, 1604.88]], ['This is a so-called quadratic optimization problem.', [1849.62, 1854.772]], ['linear sum of the samples.', [1878.77, 1881.265]], ['sums together into a double summation, so I have to keep', [1965.28, 1969.99]], ['as the sum of the alphas.', [2058.32, 2060.059]], ['this Lagrangian as--', [2111.14, 2115.56]], ['expression.', [2185.44, 2186.95]], ['optimization.', [2313.85, 2315.1]], ['optimization.', [2360.63, 2362.406]], ['into the solution, the weights on the Lagrangian multipliers', [2370.97, 2380.03]], ['gives examples that are not linearly separable, then we', [2491.85, 2497.68]], ['product of those two vectors in another space.', [2644.65, 2651.2]]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap4UxkT_ohiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Sorting the final video segments according to start time, if required\n",
        "final=sorted(final,key=lambda x:x[1][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_ybfaefoms0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "outputId": "7c84aea2-3b02-48eb-9068-64cccde83820"
      },
      "source": [
        "final"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[\"So we don't have enough constraint here to fix a\", [462.74, 465.75]],\n",
              " [\"additional constraints whether you're toward putting enough\",\n",
              "  [485.79, 493.33]],\n",
              " ['to be equal to or greater than 1.', [530.05, 531.37]],\n",
              " ['that this decision function gives the', [546.12, 548.55]],\n",
              " [\"going to add the additional constraint that it's going to\",\n",
              "  [831.14, 833.54]],\n",
              " ['some constraints.', [874.34, 876.416]],\n",
              " ['equation that constrains the samples', [1045.954, 1055.61]],\n",
              " ['Well, I decided I was going to enforce this constraint.',\n",
              "  [1134.21, 1139.27]],\n",
              " ['Then, I used the constraint to plug back some values here.',\n",
              "  [1146.105, 1149.4]],\n",
              " ['minimum of, the extremum of.', [1355.68, 1358.236]],\n",
              " [\"a function with constraints, then we're going to have to\",\n",
              "  [1408.462, 1415.922]],\n",
              " ['the constraints anymore.', [1423.35, 1425.09]],\n",
              " ['constraints.', [1456.23, 1457.48]],\n",
              " ['And then, we write down the constraint.', [1463.412, 1467.575]],\n",
              " ['So the constraint is y sub i times vector, w, dotted with',\n",
              "  [1473.83, 1489.03]],\n",
              " [\"It's back to that constraint up there, where each\", [1514.425, 1516.3]],\n",
              " ['Finding the maximum--', [1558.33, 1564.76]],\n",
              " [\"Let's take the partial of L, the Lagrangian, with respect\",\n",
              "  [1572.89, 1604.88]],\n",
              " ['This is a so-called quadratic optimization problem.', [1849.62, 1854.772]],\n",
              " ['linear sum of the samples.', [1878.77, 1881.265]],\n",
              " ['sums together into a double summation, so I have to keep',\n",
              "  [1965.28, 1969.99]],\n",
              " ['as the sum of the alphas.', [2058.32, 2060.059]],\n",
              " ['this Lagrangian as--', [2111.14, 2115.56]],\n",
              " ['expression.', [2185.44, 2186.95]],\n",
              " ['optimization.', [2313.85, 2315.1]],\n",
              " ['optimization.', [2360.63, 2362.406]],\n",
              " ['into the solution, the weights on the Lagrangian multipliers',\n",
              "  [2370.97, 2380.03]],\n",
              " ['gives examples that are not linearly separable, then we',\n",
              "  [2491.85, 2497.68]],\n",
              " ['product of those two vectors in another space.', [2644.65, 2651.2]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e1RUkbMotQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Merging the generated list if two consequtive videos are supposed to be continuous based on pre-decided threshold\n",
        "\n",
        "length=len(final)\n",
        "i=0\n",
        "while (i<(length-1)):\n",
        "  if(final[i+1][1][0]-final[i][1][1]<=60):\n",
        "    final[i][1][1]=final[i+1][1][1]\n",
        "    final.pop(i+1)\n",
        "    length-=1\n",
        "  else:\n",
        "    i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd8EBdK4tZPn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "17861706-1827-441a-8298-d94dbb15f693"
      },
      "source": [
        "final"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[\"So we don't have enough constraint here to fix a\", [462.74, 548.55]],\n",
              " [\"going to add the additional constraint that it's going to\",\n",
              "  [831.14, 876.416]],\n",
              " ['equation that constrains the samples', [1045.954, 1055.61]],\n",
              " ['Well, I decided I was going to enforce this constraint.',\n",
              "  [1134.21, 1149.4]],\n",
              " ['minimum of, the extremum of.', [1355.68, 1604.88]],\n",
              " ['This is a so-called quadratic optimization problem.', [1849.62, 1881.265]],\n",
              " ['sums together into a double summation, so I have to keep',\n",
              "  [1965.28, 1969.99]],\n",
              " ['as the sum of the alphas.', [2058.32, 2115.56]],\n",
              " ['expression.', [2185.44, 2186.95]],\n",
              " ['optimization.', [2313.85, 2380.03]],\n",
              " ['gives examples that are not linearly separable, then we',\n",
              "  [2491.85, 2497.68]],\n",
              " ['product of those two vectors in another space.', [2644.65, 2651.2]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoiOA-2wrJQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Filtering based on duration\n",
        "\n",
        "final=list(filter(lambda x:x[1][1]-x[1][0]>=7,final))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VZVcswhrKvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final=[[\"So we don't have enough constraint here to fix a\", [462.74, 548.55]],\n",
        " [\"going to add the additional constraint that it's going to\",\n",
        "  [831.14, 876.416]],\n",
        " ['equation that constrains the samples', [1045.954, 1055.61]],\n",
        " ['Well, I decided I was going to enforce this constraint.',\n",
        "  [1134.21, 1149.4]],\n",
        " ['minimum of, the extremum of.', [1355.68, 1604.88]],\n",
        " ['This is a so-called quadratic optimization problem.', [1849.62, 1881.265]],\n",
        " ['as the sum of the alphas.', [2058.32, 2115.56]],\n",
        " ['optimization.', [2313.85, 2380.03]]]"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5VPeEbmZ2jJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385,
          "referenced_widgets": [
            "c246969e9a2e4a7281c8673deaef2bab",
            "ca6a3baf47c946a98d84a9c9b351b69d",
            "8475d6e90dce440e91c0374fa3f18547",
            "df1e6fd5a4824104ada327d8fd5a5e0b",
            "cffe2a9810974d49b783f5d61208828c"
          ]
        },
        "outputId": "b944685a-aa20-4e4f-9985-11d818015dba"
      },
      "source": [
        "#Playing of results\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display,clear_output\n",
        "from IPython.display import YouTubeVideo,HTML\n",
        "button = widgets.Button(description=\"Play Next\")\n",
        "output = widgets.Output()\n",
        "x=0\n",
        "def on_button_clicked(b):\n",
        "  # Display the message within the output widget.\n",
        "  with output:\n",
        "    clear_output()\n",
        "    global x\n",
        "    s=\"https://www.youtube.com/embed/_PwhiWxHK8o?start=\"+str(int(final[x][1][0]))+\"&end=\"+str(int(final[x][1][1]))\n",
        "    #display(YouTubeVideo(s))\n",
        "    display(HTML('<iframe width=\"560\" height=\"315\" src='+s+' frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>'))\n",
        "    print(\"Result \",x+1)\n",
        "    x+=1\n",
        "    x%=len(final)\n",
        "\n",
        "button.on_click(on_button_clicked)\n",
        "display(button, output)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c246969e9a2e4a7281c8673deaef2bab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Button(description='Play Next', style=ButtonStyle())"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df1e6fd5a4824104ada327d8fd5a5e0b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6tWCsaTz14T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}